{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import docplex.cp.utils_visu as visu\n",
    "from docplex.cp.model import *\n",
    "import collections\n",
    "from io import StringIO\n",
    "from itertools import permutations\n",
    "import math\n",
    "import copy \n",
    "import chart_studio.plotly as py\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# import tensorflow as tf\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EXAMPLES = 100\n",
    "PT_MEAN = 32\n",
    "PT_STDDEV = 8\n",
    "NB_JOBS_RANGE = [20, 20]\n",
    "NB_MACHINE_RANGE = [4, 4]\n",
    "NB_DATA = 1\n",
    "NB_SETUP_TYPES = 5\n",
    "JOB_INFLATION_FACTOR = 10\n",
    "MACHINE_INFLATION_FACTOR = 10\n",
    "NB_TEST_SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_df(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(proc_t,due_dates,rel_dates,nb_m,setup_types,return_model,return_vars,return_obj=False):\n",
    "    \"\"\"\n",
    "    REF: https://ibmdecisionoptimization.github.io/tutorials/html/Scheduling_Tutorial.html\n",
    "    http://ibmdecisionoptimization.github.io/docplex-doc/cp/docplex.cp.model.py.html\n",
    "\n",
    "    Inspired by House Building Problem, hence the following terms are defined:\n",
    "\n",
    "    Worker => Machines\n",
    "    Tasks => Jobs\n",
    "    Houses => 1 (does not fulfill a purpose here)\n",
    "    Skills => each machine has the skill to process each job\n",
    "    Deadline => a day\n",
    "    \"\"\"\n",
    "    NbHouses = 1\n",
    "    Deadline =  24*60\n",
    "\n",
    "    Workers = [\"M\"+str(i) for i in range( nb_m)]\n",
    "\n",
    "    Tasks = [\"T\"+str(i) for i in range( proc_t.shape[0])]\n",
    "\n",
    "    Durations = proc_t\n",
    "    ReleaseDate = rel_dates\n",
    "    DueDate = due_dates\n",
    "\n",
    "    Skills=[]\n",
    "    for w in Workers:\n",
    "        for t in Tasks:\n",
    "            Skills.append((w,t,1))\n",
    "\n",
    "    nbWorkers = len(Workers)\n",
    "    Houses = range(NbHouses)\n",
    "    mdl5 = CpoModel()\n",
    "    tasks = {}\n",
    "    wtasks = {}\n",
    "    wseq = {}\n",
    "    transitionTimes = transition_matrix(len(Tasks))\n",
    "    for h in Houses:\n",
    "        for i,t in enumerate(Tasks):\n",
    "            # add interval decision var for each job, range from 0 to Deadline, and fixed length of PT\n",
    "            # thus each task has to fit with its pt in the fictional deadline (max time)\n",
    "            tasks[(h,t)] = mdl5.interval_var(start=[0,Deadline], size=Durations[i])\n",
    "\n",
    "            # Add transition times between tasks, which do NOT share the same setup time\n",
    "            for j,t2 in enumerate(Tasks):\n",
    "                if np.dot(setup_types[i], setup_types[j]) == 0:\n",
    "                    transitionTimes.set_value(i, j, 10)\n",
    "                else:\n",
    "                    transitionTimes.set_value(i, j, 0)\n",
    "\n",
    "        for i,s in enumerate(Skills):\n",
    "            # looping over each possible combi of machine and job (skill)\n",
    "            # add interval decision var for each combi, range from 0 to DD for each job.\n",
    "            # Thus each job on each machine must be processed within a range of 0 upto its DD.\n",
    "            # this is optional, thus do not have to be fulfilled?\n",
    "            wtasks[(h,s)] = mdl5.interval_var(start=[0,DueDate[i%len(Tasks)]],optional=True)\n",
    "        for w in Workers:\n",
    "            wseq[w] = mdl5.sequence_var([wtasks[(h,s)] for s in Skills if s[0] == w],\n",
    "                                        types=[int(s[1][1:]) for s in Skills if s[0] == w ])\n",
    "    for h in Houses:\n",
    "        for t in Tasks:\n",
    "            # add constraint such that if j is in the solution space, then there is exactly one job on a machine.\n",
    "            mdl5.add( mdl5.alternative(tasks[h,t], [wtasks[h,s] for s in Skills if s[1]==t]) )\n",
    "    for w in Workers:\n",
    "        \n",
    "        # add overlap constraint to enforce transitions is required\n",
    "        mdl5.add( mdl5.no_overlap(wseq[w], transitionTimes))\n",
    "\n",
    "    # length_of gives us the time end-start of a job, hence we minimize the time a job has to wait\n",
    "    # with is the dual problem to maximizing the time gap to its dd\n",
    "    mdl5.add(\n",
    "        mdl5.maximize(\n",
    "            mdl5.sum(mdl5.size_of(wtasks[h,s]) - mdl5.end_of(wtasks[h,s])\n",
    "                     for h in Houses for s in Skills)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Solve the model\n",
    "    solver_log_stream = StringIO()\n",
    "    msol5 = mdl5.solve(log_output=solver_log_stream)\n",
    "\n",
    "    # transform model solution to a format, which can be handled afterwards\n",
    "    worker_idx = {w : i for i,w in enumerate(Workers)}\n",
    "    worker_tasks = [[] for w in range(nbWorkers)]  # Tasks assigned to a given worker\n",
    "    for h in Houses:\n",
    "        for s in Skills:\n",
    "            worker = s[0]\n",
    "            wt = wtasks[(h,s)]\n",
    "            worker_tasks[worker_idx[worker]].append(wt)\n",
    "    sol_dict = {k: [] for k in range(nb_m)}\n",
    "\n",
    "    for i,w in enumerate(Workers):\n",
    "        visu.sequence(name=w)\n",
    "        for k,t in enumerate(worker_tasks[worker_idx[w]]):\n",
    "            wt = msol5.get_var_solution(t)\n",
    "            #print(wt)\n",
    "            if wt.is_present():\n",
    "                sol_dict[i].append((k,wt.start,wt.end))\n",
    "    for i,w in enumerate(Workers):\n",
    "        sol_dict[i].sort(key=lambda tup: tup[1])\n",
    "\n",
    "    return_list = [sol_dict]\n",
    "    if return_obj:\n",
    "        return_list.append(msol5.get_objective_values()[0])\n",
    "    if return_model:\n",
    "        return_list.append(msol5)\n",
    "    if return_vars:\n",
    "        return_list.append(transitionTimes)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_due_date(max_proc_t,nb_m,nb_t,pt_int=True):\n",
    "    proc_l=[]\n",
    "    fac_vec=np.arange(np.ceil(nb_t/2),dtype=np.int64)+1\n",
    "    fac_vec=np.repeat(fac_vec, 2)\n",
    "    print(fac_vec)\n",
    "    np.random.shuffle(fac_vec)\n",
    "\n",
    "    for i in range(nb_t):\n",
    "        t=np.random.normal(loc=(fac_vec[i]*max_proc_t[i]+max_proc_t[i]/2),scale=max_proc_t[i]/6)\n",
    "        if pt_int:\n",
    "            proc_l.append(int(t))\n",
    "        else:\n",
    "            proc_l.append(t)\n",
    "    return np.array(proc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "NB_MACHINE_RANGE = [3, 3]\n",
    "NB_JOB_RANGE = [3, 3]\n",
    "PT_MEAN = 32\n",
    "PT_STDDEV = 8\n",
    "nb_m = np.random.randint(NB_MACHINE_RANGE[0],NB_MACHINE_RANGE[1]+1) if type(NB_MACHINE_RANGE) is list else NB_MACHINE_RANGE\n",
    "nb_t = np.random.randint(NB_JOB_RANGE[0],NB_JOB_RANGE[1]+1) if type(NB_JOB_RANGE) is list else NB_JOB_RANGE\n",
    "proc_t=np.random.normal(loc=PT_MEAN,scale=PT_STDDEV,size=(NB_JOB_RANGE))\n",
    "proc_t=proc_t.astype(np.int64)\n",
    "d = gen_due_date(proc_t,nb_m,nb_t,pt_int=False)\n",
    "# print(proc_t)\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_setup_types(nb_t, nb_s):\n",
    "    # nb_s is the intended number of different setup tasks\n",
    "    setup_types = [np.random.randint(0, nb_s - 1) for _ in range(nb_t)]\n",
    "    setup_types = np.array(setup_types).reshape(-1)\n",
    "    setup_types = np.eye(nb_s)[setup_types]\n",
    "    return setup_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt(mean, stddev=0.0, size=1):\n",
    "    if stddev: \n",
    "        pt = np.random.normal(loc=mean,scale=stddev,size=size)\n",
    "        return pt.astype(np.int64)\n",
    "    return np.fill(mean, size, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(pt_mean,\n",
    "               pt_std,\n",
    "               nb_t_range,\n",
    "               nb_m_range,\n",
    "               nb_data,\n",
    "               nb_s,\n",
    "               pt_int=False,\n",
    "               return_dur=False,\n",
    "               return_pts=False):\n",
    "    # init parameters\n",
    "    # pt_mean: mean of processtime (duration of task on every machine)\n",
    "    # pt_std:std of processtime\n",
    "    # number of task range f.e. [2,10] means uniform distribution between 2 and 10 tasks\n",
    "    # number of machine range f.e. [2,10] means uniform distribution between 2 and 10 machines\n",
    "    # nb_data = number of datasamples which should get generated\n",
    "    # pt_int = (boolean) if process time is int or float (default: False)\n",
    "    # nb_s = number of setup types\n",
    "    # return_dur = process time get's return (for statistics, default:False)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    if return_dur:\n",
    "        dur=[]\n",
    "    for i in range(nb_data):\n",
    "\n",
    "        nb_m = np.random.randint(nb_m_range[0],nb_m_range[1]+1) if type(nb_m_range) is list else nb_m_range\n",
    "        nb_t = np.random.randint(nb_t_range[0],nb_t_range[1]+1) if type(nb_t_range) is list else nb_t_range\n",
    "\n",
    "        if pt_int:\n",
    "            #proc_t=np.random.normal(loc=pt_mean,scale=pt_std,size=(nb_m,nb_t))\n",
    "            proc_t=np.random.normal(loc=pt_mean,scale=pt_std,size=(nb_t))\n",
    "            proc_t=proc_t.astype(np.int64)\n",
    "        else:\n",
    "            #proc_t=np.random.normal(loc=pt_mean,scale=pt_std,size=(nb_m,nb_t))\n",
    "            proc_t=np.random.normal(loc=pt_mean,scale=pt_std,size=(nb_t))\n",
    "\n",
    "        rel_dates = np.zeros(nb_t,dtype=np.int32)\n",
    "        #due_dates=gen_due_date(np.amax(proc_t, axis=0),nb_m,nb_t)\n",
    "        due_dates = gen_due_date(proc_t,nb_m,nb_t)\n",
    "        \n",
    "        # ENABLE SETUP TYPES\n",
    "        if True:\n",
    "            setup_types = gen_setup_types(nb_t, nb_s)\n",
    "        else:\n",
    "            setup_types = np.ones([nb_t, nb_s])\n",
    "\n",
    "        x.append([{\n",
    "            'pt':proc_t,\n",
    "            'dd':due_dates,\n",
    "            'st':setup_types\n",
    "        }])\n",
    "\n",
    "        sol=solve(proc_t, due_dates, rel_dates, nb_m, setup_types,\n",
    "                  return_model=True,return_vars=True)\n",
    "        sol, model, transitionTimes = sol[:-2], sol[-2], sol[-1]\n",
    "        y.append([sol])\n",
    "        if return_dur:\n",
    "            dur.append(sol[-1])\n",
    "    if return_dur:\n",
    "        return x,y,dur\n",
    "    if return_pts:\n",
    "        return x,y,proc_t,model,transitionTimes\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▉                                                                      | 27/100 [00:00<00:00, 262.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 271.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10]\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_data = {'x': [], 'y': []}\n",
    "for i in tqdm(range(NB_EXAMPLES)):\n",
    "    try:\n",
    "        x,y = simulation(PT_MEAN,PT_STDDEV,NB_JOBS_RANGE,\n",
    "                         NB_MACHINE_RANGE,NB_DATA,NB_SETUP_TYPES,True)\n",
    "        total_data.get('x').extend(x[0])\n",
    "        total_data.get('y').extend(y[0][0])\n",
    "    except:\n",
    "        pass\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_total_data = {\n",
    "    'x': total_data.get('x'),\n",
    "    'y': total_data.get('y')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "data_x = []\n",
    "for example in range(len(inf_total_data.get('x'))):\n",
    "    data_x_point = []\n",
    "    point = inf_total_data.get('x')[example]\n",
    "    for i in range(len(point.get('pt'))):\n",
    "        t = [point.get('pt')[i], point.get('dd')[i]]\n",
    "        t.extend(point.get('st')[i])\n",
    "        data_x_point.append(t)\n",
    "    data_x.append(data_x_point)\n",
    "data_x = np.array(data_x, np.object)\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "for example in range(len(inf_total_data.get('y'))):\n",
    "    point = inf_total_data.get('y')[example]\n",
    "    t = [point[m] for m in range(len(point.keys()))]\n",
    "    data_y.append(t)\n",
    "data_y = np.array(data_y, np.object)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding input to get equal input job number\n",
    "def pad_jobs(x):\n",
    "    job_pad = np.append(np.array([-1, -1]), np.zeros(NB_SETUP_TYPES))\n",
    "    padded_x = np.empty([len(list(x)), max(NB_JOBS_RANGE), len(job_pad)])\n",
    "    padded_x[:] = job_pad\n",
    "    for i in range(len(x)):\n",
    "        padded_x[i, :len(x[i]), :] = x[i]\n",
    "    return padded_x\n",
    "\n",
    "# padding output to get equal machine number\n",
    "# and jobs assigned to it\n",
    "def pad_machines(y):\n",
    "    job_pad = np.array([-1, -1, -1], np.float32)\n",
    "    y_padded = np.zeros([len(y), max(NB_MACHINE_RANGE), max(NB_JOBS_RANGE), len(job_pad)])\n",
    "    y_padded[:] = job_pad\n",
    "    for i in range(len(y)):\n",
    "        for m in range(len(y[i])):\n",
    "            if len(y[i][m]) > 0:\n",
    "                y_padded[i, m, :len(y[i][m]), :] = y[i][m]\n",
    "    return y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20, 7)\n",
      "(0, 3, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "data_x = pad_jobs(data_x)\n",
    "data_y = pad_machines(data_y)\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "# add ID to jobs\n",
    "data_x_copy = np.ones([data_x.shape[0], data_x.shape[1], data_x.shape[2]+1])\n",
    "for i in range(len(data_x)):\n",
    "    for j in range(len(data_x[i])):\n",
    "        data_x_copy[i, j] = np.insert(data_x[i, j], 0, j)\n",
    "data_x = data_x_copy\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical order for y to cut down the solution space\n",
    "# sort by the first job id on each machine\n",
    "# since when we consider an iterative solving alg, this sort style can be learned \n",
    "# even iteratively\n",
    "data_y_copy = np.copy(data_y)\n",
    "# print(data_y[0])\n",
    "for i in range(len(data_y)):\n",
    "    minima = []\n",
    "    for m in range(len(data_y[i])):\n",
    "        arr = data_y_copy[i,m,0,0]\n",
    "        minimum = np.where(arr >= 0, arr, np.inf).min()\n",
    "        minima.append(minimum)\n",
    "    m_perm = np.argsort(minima)\n",
    "    for m in range(len(data_y[i])):\n",
    "        data_y[i, m] = data_y_copy[i, m_perm[m]]\n",
    "# print(data_y[0]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_swap_inflation(samples: np.array, inflation_factor=10):\n",
    "    inflated_samples = []\n",
    "    perm_keys = []\n",
    "    for i, sample in enumerate(samples):\n",
    "            \n",
    "        # randomly sample from the permutation set\n",
    "        rnd_perms_keys = [np.random.permutation(len(sample)) for _ in range(inflation_factor)]\n",
    "        perm_keys.append(rnd_perms_keys)\n",
    "        \n",
    "        # add combis to the inflation list\n",
    "        for perm_key in rnd_perms_keys:\n",
    "            inflated_sample = np.empty(sample.shape)\n",
    "            inflated_sample[:, 0] = np.array([sample[i, 0] for i in perm_key])\n",
    "            inflated_sample[:, 1] = np.array([sample[i, 1] for i in perm_key])\n",
    "            inflated_sample[:, 2] = np.array([sample[i, 2] for i in perm_key])\n",
    "            inflated_sample[:, 1:] = np.array([sample[i, 1:] for i in perm_key])\n",
    "            inflated_samples.append(inflated_sample)\n",
    "            \n",
    "    return np.array(inflated_samples), np.squeeze(perm_keys)\n",
    "\n",
    "\n",
    "def machine_swap_inflation(labels: np.array) -> np.array:\n",
    "    inflated_labels = []\n",
    "    for i, label in enumerate(labels):\n",
    "            \n",
    "            machine_alloc = label\n",
    "            perms = permutations(np.arange(max(NB_MACHINE_RANGE)))\n",
    "            for perm in perms:\n",
    "                inflated_label = [machine_alloc[k] for k in perm]\n",
    "                inflated_labels.append(inflated_label)\n",
    "            \n",
    "    return np.array(inflated_labels)\n",
    "\n",
    "\n",
    "def inflate_ds(data, job_inflation_factor=10, machine_inflation_factor=10):\n",
    "    inf_data = ([], [])\n",
    "    data_x, data_y = data\n",
    "    for x, y in tqdm(zip(data_x, data_y)):\n",
    "        \n",
    "        # inflate x and y\n",
    "        x_job_inf, perm_keys = job_swap_inflation([x], inflation_factor=job_inflation_factor)\n",
    "        # y_mas_inf = machine_swap_inflation([y])\n",
    "        \n",
    "        # assign random ys sampled from the inflated set to random jobs of the inflated set\n",
    "        # Note that under the assumption that the previous inflation is correct, \n",
    "        # switching the high level ordering of the inflated samples and labels, does\n",
    "        # NOT lead to infeasible examples, since all combinations are feasible anyway\n",
    "#         y_idxs = np.random.randint(len(y_mas_inf), size=machine_inflation_factor)\n",
    "        \n",
    "        # when the job list is inflated after padding, the ids in the machine labels are also shuffled\n",
    "        # to encounter for this, we change only the indexes in the machine label lists \n",
    "#         inf_data_y = [y_mas_inf[i] for i in y_idxs]\n",
    "\n",
    "#         inf_data_y = np.array(inf_data_y)\n",
    "#         for i in range(len(inf_data_y)):\n",
    "#             for m in range(len(inf_data_y[i])):\n",
    "#                 for j in range(len(inf_data_y[i][m])):\n",
    "#                     if inf_data_y[i, m, j, 0] != -1:\n",
    "#                         old = inf_data_y[i, m, j, 0]\n",
    "#                         inf_data_y[i, m, j, 0] = list(perm_keys[i]).index(old)\n",
    "\n",
    "        inf_data[0].extend(x_job_inf)\n",
    "        inf_data[1].extend([y for _ in range(job_inflation_factor)])\n",
    "        \n",
    "    return inf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (inf_data_x, inf_data_y) = inflate_ds((data_x, data_y),\n",
    "#                                       job_inflation_factor=JOB_INFLATION_FACTOR,\n",
    "#                                       machine_inflation_factor=MACHINE_INFLATION_FACTOR)\n",
    "# inf_data_x = np.array(inf_data_x)\n",
    "# inf_data_x = np.concatenate((inf_data_x, data_x))\n",
    "# inf_data_y = np.array(inf_data_y)\n",
    "# inf_data_y = np.concatenate((inf_data_y, data_y))\n",
    "# print(inf_data_x.shape)\n",
    "# print(inf_data_y.shape)\n",
    "# print(inf_data_x[0])\n",
    "# print(inf_data_y[0])\n",
    "inf_data_x = data_x\n",
    "inf_data_y = data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_valid_ms(y):\n",
    "    return sum(y[:, 0, 0] != -1)\n",
    "    \n",
    "def check_point_validity(x, y):\n",
    "#     id = x[:, 0] \n",
    "    pt = x[:, 0]    \n",
    "    dd = x[:, 1]\n",
    "    st = x[:, 2:]\n",
    "    rd = np.zeros(len(pt), dtype=np.int32)\n",
    "    nb_m = y_valid_ms(y)\n",
    "    \n",
    "    # remove padding \n",
    "    pt = pt[pt != -1].astype(np.int32)\n",
    "    dd = dd[dd != -1].astype(np.int32)\n",
    "    st = st[np.sum(st, axis=1) != 0, :]\n",
    "    \n",
    "    y_hat = solve(pt,dd,rd,nb_m,st,False,False,False)\n",
    "\n",
    "    y_makespan = np.amax(y[:, :, 1])\n",
    "    \n",
    "    rd_y_hat = [np.array(alloc)[:, 2] for alloc in list(y_hat[0].values())]\n",
    "    y_hat_makespan = max(list(chain(*chain(rd_y_hat))))\n",
    "    \n",
    "    return {'y': y_makespan, 'y_solver': float(y_hat_makespan), 'valid': y_makespan <= y_hat_makespan}\n",
    "\n",
    "def random_validity_check(ds, nb_samples=10):\n",
    "    ds_x, ds_y = ds\n",
    "    rand_sample_idxs = np.random.randint(len(ds_x), size=nb_samples)\n",
    "    results = [check_point_validity(ds_x[idx], ds_y[idx]) for idx in tqdm(rand_sample_idxs)]\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_validity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43minf_data_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minf_data_y\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m display(df) \n",
      "Cell \u001B[0;32mIn[64], line 28\u001B[0m, in \u001B[0;36mrandom_validity_check\u001B[0;34m(ds, nb_samples)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrandom_validity_check\u001B[39m(ds, nb_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m     27\u001B[0m     ds_x, ds_y \u001B[38;5;241m=\u001B[39m ds\n\u001B[0;32m---> 28\u001B[0m     rand_sample_idxs \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mds_x\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     results \u001B[38;5;241m=\u001B[39m [check_point_validity(ds_x[idx], ds_y[idx]) \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m tqdm(rand_sample_idxs)]\n\u001B[1;32m     30\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results)\n",
      "File \u001B[0;32mmtrand.pyx:745\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.randint\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_bounded_integers.pyx:1254\u001B[0m, in \u001B[0;36mnumpy.random._bounded_integers._rand_int64\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: low >= high"
     ]
    }
   ],
   "source": [
    "df = random_validity_check((inf_data_x, inf_data_y), nb_samples=5)\n",
    "display(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m y_ele \u001B[38;5;241m=\u001B[39m \u001B[43minf_data_y\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mdict\u001B[39m(Task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJob \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(i),\n\u001B[1;32m      4\u001B[0m          Start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(datetime(\u001B[38;5;241m2020\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mint\u001B[39m(y_ele[m][i][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m60\u001B[39m), \u001B[38;5;28mint\u001B[39m(y_ele[m][i][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m60\u001B[39m))),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m         ) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y_ele)) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y_ele[m])) \u001B[38;5;28;01mif\u001B[39;00m y_ele[m][i][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \n\u001B[1;32m      8\u001B[0m ])\n\u001B[1;32m      9\u001B[0m print_full_df(df)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "y_ele = inf_data_y[0]\n",
    "df = pd.DataFrame([\n",
    "    dict(Task=\"Job \"+str(i),\n",
    "         Start=str(datetime(2020, 1, 1, int(y_ele[m][i][1]//60), int(y_ele[m][i][1]%60))),\n",
    "         Finish=str(datetime(2020, 1, 1, int(y_ele[m][i][2]//60), int(y_ele[m][i][2]%60))),\n",
    "         Resource=str(m)\n",
    "        ) for m in range(len(y_ele)) for i in range(len(y_ele[m])) if y_ele[m][i][0] != -1 \n",
    "])\n",
    "print_full_df(df)\n",
    "\n",
    "fig = px.timeline(df, x_start=\"Start\", x_end=\"Finish\", y=\"Resource\", color=\"Resource\")\n",
    "fig.show()\n",
    "print(inf_data_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of labels y\n",
    "def one_hot_encoder(y):\n",
    "    M = max(NB_MACHINE_RANGE)\n",
    "    J = max(NB_JOBS_RANGE)\n",
    "    y_data_one_hot = np.zeros([len(y), M, J, J])\n",
    "    for i in tqdm(range(len(y))):\n",
    "        for m in range(M):\n",
    "            for j in range(J):\n",
    "                one_hot = np.zeros(J)\n",
    "                idx = int(y[i, m, j, 0])\n",
    "                one_hot[idx] = 1 if idx != -1 else 0\n",
    "                y_data_one_hot[i, m, j] = one_hot\n",
    "    y = np.transpose(y_data_one_hot, [0, 1, 3, 2])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20, 8)\n",
      "(0, 3, 20, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pad_inf_data_x = inf_data_x\n",
    "pad_inf_data_y = one_hot_encoder(inf_data_y)\n",
    "print(pad_inf_data_x.shape)\n",
    "print(pad_inf_data_y.shape)\n",
    "# print(inf_data_y[20])\n",
    "# print(pad_inf_data_y[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'j'+str(j): x[j] for j in range(len(x))} for x in pad_inf_data_x)\n",
    "df.to_pickle('x.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'm'+str(m): {'j'+str(j): y[m][j] for j in range(len(y[m]))}\n",
    "for m in range(len(y))} for y in pad_inf_data_y)\n",
    "df.to_pickle('y.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = 'x.data'\n",
    "y_path = 'y.data'\n",
    "\n",
    "# x_path = '../../../../learner/res/ds/processed/setup_types/fixed_4m12j_setup_no_augm/x_large.data'\n",
    "# y_path = '../../../../learner/res/ds/processed/setup_types/fixed_4m12j_setup_no_augm/y_large.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[1;32m      4\u001B[0m     x\u001B[38;5;241m.\u001B[39mappend([df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mj\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(job)][example] \u001B[38;5;28;01mfor\u001B[39;00m job \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])])\n\u001B[0;32m----> 5\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x, tf\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_pickle(x_path))\n",
    "x = []\n",
    "for example in range(df.shape[0]):\n",
    "    x.append([df['j'+str(job)][example] for job in range(df.shape[1])])\n",
    "x = tf.convert_to_tensor(x, tf.float32)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[74], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m         y_m\u001B[38;5;241m.\u001B[39mappend([df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(m)][example][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mj\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(j)] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(j_length)])\n\u001B[1;32m      8\u001B[0m     y\u001B[38;5;241m.\u001B[39mappend(y_m)\n\u001B[0;32m----> 9\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mconvert_to_tensor(y, tf\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(y\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_pickle(y_path))\n",
    "y = []\n",
    "for example in range(df.shape[0]):\n",
    "    y_m = []\n",
    "    for m in range(df.shape[1]):\n",
    "        j_length = len(df['m'+str(m)][example].keys())\n",
    "        y_m.append([df['m'+str(m)][example]['j'+str(j)] for j in range(j_length)])\n",
    "    y.append(y_m)\n",
    "y = tf.convert_to_tensor(y, tf.float32)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[75], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m                     y_dense[i, m, t, :\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m (padding_value, padding_value)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y_dense\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m---> 18\u001B[0m y_dense \u001B[38;5;241m=\u001B[39m \u001B[43msparse_to_dense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[75], line 4\u001B[0m, in \u001B[0;36msparse_to_dense\u001B[0;34m(x, y, padding_value)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msparse_to_dense\u001B[39m(x, y, padding_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m()\n\u001B[1;32m      5\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m      6\u001B[0m     M \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mshape(y)[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def sparse_to_dense(x, y, padding_value=-1):\n",
    "    y = y.numpy()\n",
    "    x = x.numpy()\n",
    "    M = tf.shape(y)[1]\n",
    "    T = tf.shape(y)[-2]\n",
    "    B = tf.shape(y)[0]\n",
    "    y_dense = np.empty([B, M, T, 7])\n",
    "    for i in range(len(y)):\n",
    "        for m in range(M):\n",
    "            y_dense[i, m, :] = np.matmul(y[i, m].T, x[i, :, :])\n",
    "            for t in range(T):\n",
    "                if y_dense[i, m, t, 0] == 0:\n",
    "                    y_dense[i, m, t, :2] = (padding_value, padding_value)\n",
    "    return y_dense.astype(np.float32)\n",
    "\n",
    "y_dense = sparse_to_dense(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m class_counts \u001B[38;5;241m=\u001B[39m \u001B[43my_dense\u001B[49m[:, :, :, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      2\u001B[0m unique, counts \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39munique(class_counts, return_counts\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m class_counts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(unique, counts))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_dense' is not defined"
     ]
    }
   ],
   "source": [
    "class_counts = y_dense[:, :, :, 0]\n",
    "unique, counts = numpy.unique(class_counts, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "class_counts.pop(-1.0)\n",
    "\n",
    "pt_distr = y_dense[:, :, :, 0].flatten()\n",
    "pt_distr = pt_distr[pt_distr != -1]\n",
    "\n",
    "dd_distr = y_dense[:, :, :, 1].flatten()\n",
    "dd_distr = dd_distr[dd_distr != -1]\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(x=pt_distr, histnorm='probability', name='pt'))\n",
    "fig.add_trace(go.Histogram(x=dd_distr, histnorm='probability', name='dd'))\n",
    "fig.update_layout(title=\"PT/DD Distr.\", barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Not needed!\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m y_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty([\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m0\u001B[39m], y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m]])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y)):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y[i])):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Not needed!\n",
    "y_idx = np.empty([y.shape[0], y.shape[1], y.shape[2]])\n",
    "for i in range(len(y)):\n",
    "    for m in range(len(y[i])):\n",
    "        for j in range(len(y[i,m])):\n",
    "            y_idx[i,m,j] = -1 if np.sum(y[i,m,j]) == 0 else np.where(y[i,m,j] == 1)[0][0]\n",
    "\n",
    "# i x m x j -> int means time pos\n",
    "print(y_idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2734/1428540441.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>div.output_scroll { height: 100em; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[78], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m display, HTML\n\u001B[1;32m      2\u001B[0m display(HTML(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<style>div.output_scroll \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m height: 100em; }</style>\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m      5\u001B[0m     fig \u001B[38;5;241m=\u001B[39m go\u001B[38;5;241m.\u001B[39mFigure(data\u001B[38;5;241m=\u001B[39mgo\u001B[38;5;241m.\u001B[39mHeatmap(\n\u001B[1;32m      6\u001B[0m             z\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39msum(y[:, i, :, :], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m),\n\u001B[1;32m      7\u001B[0m             x\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m]),\n\u001B[1;32m      8\u001B[0m             y\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m]),\n\u001B[1;32m      9\u001B[0m             colorscale\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mViridis\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     11\u001B[0m     fig\u001B[38;5;241m.\u001B[39mupdate_layout(title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClass Distr. M\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i), height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 100em; }</style>\"))\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "            z=np.sum(y[:, i, :, :], axis=0),\n",
    "            x=np.arange(y.shape[2]),\n",
    "            y=np.arange(y.shape[2]),\n",
    "            colorscale='Viridis'))\n",
    "\n",
    "    fig.update_layout(title='Class Distr. M{}'.format(i), height=300)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
